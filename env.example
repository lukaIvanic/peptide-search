# Application
APP_NAME="Peptide Literature Extractor"
ENV=development

# Database
# For a file in project root:
DB_URL=sqlite:///peptide_search.db

# LLM Provider: mock | openai | openai-full | openai-mini | openai-nano | deepseek | gemini | openrouter
LLM_PROVIDER=mock

# OpenAI configuration (required if LLM_PROVIDER=openai)
# GPT-4o can process PDF URLs directly without text extraction!
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o
OPENAI_MODEL_MINI=gpt-5-mini
OPENAI_MODEL_NANO=gpt-5-nano

# DeepSeek configuration (required if LLM_PROVIDER=deepseek)
DEEPSEEK_API_KEY=
DEEPSEEK_MODEL=deepseek-chat

# Gemini configuration (required if LLM_PROVIDER=gemini)
GEMINI_API_KEY=
GEMINI_MODEL=gemini-2.5-flash

# OpenRouter configuration (required if LLM_PROVIDER=openrouter)
OPENROUTER_API_KEY=
OPENROUTER_MODEL=openai/gpt-4o-mini

# Upload storage (optional — defaults to system temp dir; set to a persistent path on Render)
# UPLOAD_TTL_SECONDS: how long uploaded PDFs are kept on disk before purging (default: 86400 = 24h)
# Uploaded files are NOT deleted on first read anymore — they survive failed retries until TTL expires.
# On Render with a persistent disk, set this to e.g. /var/data/uploads
# UPLOAD_DIR=/var/data/uploads

# Prompting
# MAX_TOKENS controls max LLM output tokens. Too low → truncated JSON → parse failures.
# Recommended: 8192+ for Gemini/OpenAI. Default is 8192.
MAX_TOKENS=100000
TEMPERATURE=0.2
INCLUDE_DEFINITIONS=true

# Queue / runtime
# Number of concurrent extraction workers. Keep low on memory-constrained instances (e.g. 4 on Render Starter 512MB).
QUEUE_CONCURRENCY=4
QUEUE_CLAIM_TIMEOUT_SECONDS=300
QUEUE_CLAIM_HEARTBEAT_SECONDS=30
QUEUE_RECOVERY_INTERVAL_SECONDS=30
QUEUE_MAX_ATTEMPTS=3
QUEUE_ENGINE_VERSION=v2

# Optional DB bootstrap for first deploy on persistent disk (Render)
DB_BOOTSTRAP_ON_EMPTY=false
DB_BOOTSTRAP_SNAPSHOT=/opt/render/project/src/deploy/seed/peptide_search.db
DB_BOOTSTRAP_TARGET=/var/data/peptide_search.db

# Provider model discovery cache TTL (seconds)
PROVIDER_MODEL_CACHE_TTL_SECONDS=900

# API access gate (for demo deployments)
ACCESS_GATE_ENABLED=false
ACCESS_GATE_USERNAME=
ACCESS_GATE_PASSWORD=

# CORS (optional, comma-separated origins when frontend is hosted separately)
CORS_ORIGINS=
